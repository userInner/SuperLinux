"""Simplified agent that works without MCP subprocess."""

import asyncio
import json
import uuid
from typing import Any
from enum import Enum

from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage

from .common.config import AgentConfig
from .orchestrator.llm_engine import create_llm_engine
from .tools import execute_tool, get_all_tools
from .prompts import get_prompt


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    IN_PROGRESS = "in_progress"      # è¿›è¡Œä¸­
    COMPLETED = "completed"          # å·²å®Œæˆ
    FAILED = "failed"                # å¤±è´¥
    NEEDS_INPUT = "needs_input"      # éœ€è¦ç”¨æˆ·è¾“å…¥
    BLOCKED = "blocked"              # è¢«é˜»å¡


class SimpleLinuxAgent:
    """åŸºäºä»»åŠ¡å®ŒæˆçŠ¶æ€çš„æ™ºèƒ½ Agentã€‚
    
    æ ¸å¿ƒç†å¿µï¼šä»¥é—®é¢˜è§£å†³ä¸ºå¯¼å‘ï¼Œè€Œä¸æ˜¯è¿­ä»£æ¬¡æ•°é™åˆ¶ã€‚
    Agent ä¼šæŒç»­å·¥ä½œç›´åˆ°ï¼š
    1. ä»»åŠ¡å®Œæˆ
    2. éœ€è¦ç”¨æˆ·è¾“å…¥
    3. é‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜
    """
    
    def __init__(
        self,
        llm_provider: str = "deepseek",
        llm_model: str = "deepseek-chat",
        api_key: str = "",
        max_retries_per_error: int = 3,
        prompt_type: str = "default"
    ):
        self.llm_engine = create_llm_engine(
            provider=llm_provider,
            model=llm_model,
            api_key=api_key
        )
        self.tools = get_all_tools()
        self.llm_with_tools = None
        self._current_thread_id = str(uuid.uuid4())
        self.max_retries_per_error = max_retries_per_error
        self.prompt_type = prompt_type
    
    async def initialize(self) -> None:
        """Initialize the agent with tools."""
        self.llm_with_tools = self.llm_engine.bind_tools(self.tools)
        print(f"âœ… Agent initialized with {len(self.tools)} tools:")
        for tool in self.tools:
            print(f"   - {tool.name}: {tool.description[:40]}...")
    
    def _get_task_oriented_prompt(self) -> str:
        """è·å–ä»¥ä»»åŠ¡ä¸ºå¯¼å‘çš„ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = get_prompt(self.prompt_type)
        
        task_completion_instructions = """

## ä»»åŠ¡å®Œæˆæœºåˆ¶

ä½ å¿…é¡»åœ¨å›å¤ä¸­æ˜ç¡®æ ‡æ³¨ä»»åŠ¡çŠ¶æ€ã€‚åœ¨ä½ çš„æœ€ç»ˆå›å¤æœ«å°¾ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š

- `[STATUS: COMPLETED]` - ä»»åŠ¡å·²å®Œæˆï¼Œç”¨æˆ·çš„é—®é¢˜å·²è§£å†³
- `[STATUS: NEEDS_INPUT]` - éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯æ‰èƒ½ç»§ç»­
- `[STATUS: FAILED: åŸå› ]` - ä»»åŠ¡å¤±è´¥ï¼Œè¯´æ˜åŸå› 
- `[STATUS: IN_PROGRESS]` - ä»»åŠ¡ä»åœ¨è¿›è¡Œä¸­ï¼Œéœ€è¦ç»§ç»­æ‰§è¡Œå·¥å…·

### é‡è¦è§„åˆ™

1. **æŒç»­å·¥ä½œç›´åˆ°å®Œæˆ**: å¦‚æœä»»åŠ¡æœªå®Œæˆï¼Œç»§ç»­è°ƒç”¨å·¥å…·ï¼Œä¸è¦åœæ­¢
2. **ä¸è¦è¿‡æ—©ç»“æŸ**: åªæœ‰å½“ä½ ç¡®ä¿¡é—®é¢˜å·²è§£å†³æ—¶æ‰æ ‡è®° COMPLETED
3. **ä¸»åŠ¨è§£å†³é—®é¢˜**: é‡åˆ°é”™è¯¯æ—¶ï¼Œå…ˆå°è¯•æœç´¢è§£å†³æ–¹æ¡ˆï¼Œä¸è¦ç«‹å³æ”¾å¼ƒ
4. **æ¸…æ™°æ²Ÿé€š**: å¦‚æœéœ€è¦ç”¨æˆ·è¾“å…¥ï¼Œæ˜ç¡®è¯´æ˜éœ€è¦ä»€ä¹ˆä¿¡æ¯

### åˆ¤æ–­ä»»åŠ¡å®Œæˆçš„æ ‡å‡†

- ç”¨æˆ·è¦æ±‚çš„æ“ä½œå·²æ‰§è¡ŒæˆåŠŸ
- ç”¨æˆ·çš„é—®é¢˜å·²å¾—åˆ°å›ç­”
- æ‰€æœ‰å¿…è¦çš„æ­¥éª¤éƒ½å·²å®Œæˆ
- ç»“æœå·²å‘ç”¨æˆ·å±•ç¤º

### ç¤ºä¾‹

ç”¨æˆ·: "æŸ¥çœ‹ç³»ç»Ÿå†…å­˜ä½¿ç”¨æƒ…å†µ"
â†’ è°ƒç”¨ get_memory_info
â†’ å±•ç¤ºç»“æœ
â†’ [STATUS: COMPLETED]

ç”¨æˆ·: "å®‰è£… nginx"
â†’ è°ƒç”¨ run_command å®‰è£…
â†’ å¦‚æœå¤±è´¥ï¼Œæœç´¢è§£å†³æ–¹æ¡ˆ
â†’ é‡è¯•æˆ–æŠ¥å‘Šé—®é¢˜
â†’ [STATUS: COMPLETED] æˆ– [STATUS: FAILED: åŸå› ]
"""
        return base_prompt + task_completion_instructions
    
    def _parse_status(self, content: str) -> tuple[TaskStatus, str]:
        """ä»å›å¤ä¸­è§£æä»»åŠ¡çŠ¶æ€"""
        content_lower = content.lower()
        
        if "[status: completed]" in content_lower:
            return TaskStatus.COMPLETED, content.replace("[STATUS: COMPLETED]", "").strip()
        elif "[status: needs_input]" in content_lower:
            return TaskStatus.NEEDS_INPUT, content.replace("[STATUS: NEEDS_INPUT]", "").strip()
        elif "[status: failed" in content_lower:
            return TaskStatus.FAILED, content
        elif "[status: in_progress]" in content_lower:
            return TaskStatus.IN_PROGRESS, content.replace("[STATUS: IN_PROGRESS]", "").strip()
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çŠ¶æ€ï¼Œæ ¹æ®å†…å®¹åˆ¤æ–­
        # æœ‰å·¥å…·è°ƒç”¨ = è¿›è¡Œä¸­ï¼Œæ— å·¥å…·è°ƒç”¨ = å¯èƒ½å®Œæˆ
        return TaskStatus.IN_PROGRESS, content
    
    async def chat(self, message: str) -> str:
        """åŸºäºä»»åŠ¡å®ŒæˆçŠ¶æ€çš„å¯¹è¯å¾ªç¯"""
        if not self.llm_with_tools:
            await self.initialize()
        
        system_prompt = self._get_task_oriented_prompt()
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=message)
        ]
        
        # é”™è¯¯è¿½è¸ª
        error_tracker = {}  # {error_type: count}
        total_tool_calls = 0
        consecutive_no_progress = 0
        last_tool_results = []
        
        while True:
            # è°ƒç”¨ LLM
            response = await self.llm_with_tools.ainvoke(messages)
            messages.append(response)
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥çŠ¶æ€å¹¶è¿”å›
            if not response.tool_calls:
                status, clean_content = self._parse_status(response.content)
                
                if status == TaskStatus.COMPLETED:
                    print("   âœ… Task completed")
                    return clean_content
                elif status == TaskStatus.NEEDS_INPUT:
                    print("   â“ Needs user input")
                    return clean_content
                elif status == TaskStatus.FAILED:
                    print("   âŒ Task failed")
                    return clean_content
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ä½†ä¹Ÿæ²¡æœ‰æ˜ç¡®å®ŒæˆçŠ¶æ€
                    # å¯èƒ½æ˜¯ LLM å¿˜è®°æ ‡è®°äº†ï¼Œå‡è®¾å·²å®Œæˆ
                    consecutive_no_progress += 1
                    if consecutive_no_progress >= 2:
                        return response.content
                    # æé†’ LLM æ ‡è®°çŠ¶æ€
                    messages.append(HumanMessage(
                        content="è¯·ç¡®è®¤ä»»åŠ¡æ˜¯å¦å®Œæˆï¼Œå¹¶åœ¨å›å¤æœ«å°¾æ ‡æ³¨çŠ¶æ€ [STATUS: COMPLETED] æˆ–ç»§ç»­æ‰§è¡Œã€‚"
                    ))
                    continue
            
            # é‡ç½®æ— è¿›å±•è®¡æ•°
            consecutive_no_progress = 0
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            current_results = []
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]
                
                total_tool_calls += 1
                print(f"   ğŸ”§ [{total_tool_calls}] {tool_name}")
                if tool_args:
                    args_str = str(tool_args)
                    if len(args_str) > 60:
                        args_str = args_str[:60] + "..."
                    print(f"      Args: {args_str}")
                
                # æ‰§è¡Œå·¥å…·
                result = await execute_tool(tool_name, tool_args)
                current_results.append((tool_name, result))
                
                # æ£€æŸ¥é”™è¯¯
                try:
                    result_data = json.loads(result)
                    is_error = result_data.get("error", False)
                    error_msg = result_data.get("message", "")
                except:
                    is_error = False
                    error_msg = ""
                
                if is_error:
                    # è¿½è¸ªé”™è¯¯
                    error_key = f"{tool_name}:{error_msg[:50]}"
                    error_tracker[error_key] = error_tracker.get(error_key, 0) + 1
                    
                    print(f"   âŒ Error: {error_msg[:60]}")
                    
                    # æ£€æŸ¥æ˜¯å¦é‡å¤é”™è¯¯å¤ªå¤šæ¬¡
                    if error_tracker[error_key] >= self.max_retries_per_error:
                        # æ·»åŠ æç¤ºè®© LLM ä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£
                        hint = f"""
è¿™ä¸ªé”™è¯¯å·²ç»å‡ºç° {error_tracker[error_key]} æ¬¡äº†: {error_msg}

è¯·æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•è§£å†³:
1. **ä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£**: ä½¿ç”¨ web_search æœç´¢ "å®˜æ–¹æ–‡æ¡£ + å…³é”®è¯" æˆ– "official docs + keyword"
2. ä½¿ç”¨ fetch_webpage è·å–å®˜æ–¹æ–‡æ¡£çš„è¯¦ç»†å†…å®¹
3. æ ¹æ®å®˜æ–¹æ–‡æ¡£çš„æŒ‡å¯¼é‡æ–°å°è¯•
4. å¦‚æœå®˜æ–¹æ–‡æ¡£æ²¡æœ‰ç­”æ¡ˆï¼Œå†æœç´¢ç¤¾åŒºè§£å†³æ–¹æ¡ˆ
5. å¦‚æœç¡®å®æ— æ³•è§£å†³ï¼Œæ ‡è®° [STATUS: FAILED: åŸå› ]
"""
                        messages.append(ToolMessage(content=result, tool_call_id=tool_id))
                        messages.append(HumanMessage(content=hint))
                        continue
                else:
                    print(f"   âœ“ Success")
                
                messages.append(ToolMessage(content=result, tool_call_id=tool_id))
            
            # æ£€æµ‹å¾ªç¯ï¼ˆç›¸åŒçš„å·¥å…·è°ƒç”¨äº§ç”Ÿç›¸åŒçš„ç»“æœï¼‰
            if current_results == last_tool_results:
                consecutive_no_progress += 1
                if consecutive_no_progress >= 3:
                    messages.append(HumanMessage(
                        content="æ£€æµ‹åˆ°é‡å¤æ“ä½œã€‚è¯·å°è¯•ä¸åŒçš„æ–¹æ³•ï¼Œæˆ–è€…å¦‚æœä»»åŠ¡å·²å®Œæˆè¯·æ ‡è®° [STATUS: COMPLETED]ã€‚"
                    ))
            else:
                last_tool_results = current_results
    
    async def run_interactive(self) -> None:
        """Run in interactive mode."""
        await self.initialize()
        
        print("\n" + "=" * 60)
        print("ğŸ¤– Linux Agent - ä»»åŠ¡å¯¼å‘æ¨¡å¼")
        print("=" * 60)
        print("ç‰¹æ€§: æŒç»­å·¥ä½œç›´åˆ°ä»»åŠ¡å®Œæˆ")
        print("è¾“å…¥ 'quit' é€€å‡º, 'help' æŸ¥çœ‹å¸®åŠ©")
        print("-" * 60 + "\n")
        
        while True:
            try:
                user_input = input("You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ("quit", "exit"):
                    print("\nGoodbye! ğŸ‘‹")
                    break
                
                if user_input.lower() == "help":
                    print("""
å¯ç”¨å‘½ä»¤ç¤ºä¾‹:
  - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  - æ£€æŸ¥ nginx æœåŠ¡çŠ¶æ€
  - æœç´¢ Docker å®‰è£…æ•™ç¨‹
  - æ‰§è¡Œ df -h å‘½ä»¤
  - å¦‚ä½•é…ç½® SSH å…å¯†ç™»å½•
  - åˆ›å»ºä¸€ä¸ª Python è„šæœ¬æ¥ç›‘æ§ CPU
""")
                    continue
                
                print("\nğŸ¤” Working on your task...\n")
                response = await self.chat(user_input)
                print(f"\nAgent: {response}\n")
                
            except KeyboardInterrupt:
                print("\n\nâš ï¸ Interrupted. Type 'quit' to exit.\n")
            except EOFError:
                print("\nGoodbye! ğŸ‘‹")
                break


async def main():
    """Main entry point."""
    import os
    import sys
    
    # Get API key from environment
    api_key = os.environ.get("DEEPSEEK_API_KEY", "")
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")
        provider = "openai"
        model = "gpt-4o"
    else:
        provider = "deepseek"
        model = "deepseek-chat"
    
    if not api_key:
        print("Error: Please set DEEPSEEK_API_KEY or OPENAI_API_KEY")
        sys.exit(1)
    
    agent = SimpleLinuxAgent(
        llm_provider=provider,
        llm_model=model,
        api_key=api_key,
        max_retries_per_error=3,
        prompt_type="default"
    )
    
    await agent.run_interactive()


if __name__ == "__main__":
    asyncio.run(main())
