"""Simplified agent that works without MCP subprocess."""

import asyncio
import json
import uuid
from typing import Any

from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage

from .common.config import AgentConfig
from .orchestrator.llm_engine import create_llm_engine
from .tools import execute_tool, get_all_tools


class SimpleLinuxAgent:
    """Simplified agent with auto-retry and search fallback."""
    
    def __init__(
        self,
        llm_provider: str = "deepseek",
        llm_model: str = "deepseek-chat",
        api_key: str = "",
        max_retries: int = 3
    ):
        self.llm_engine = create_llm_engine(
            provider=llm_provider,
            model=llm_model,
            api_key=api_key
        )
        self.tools = get_all_tools()
        self.llm_with_tools = None
        self._current_thread_id = str(uuid.uuid4())
        self.max_retries = max_retries
    
    async def initialize(self) -> None:
        """Initialize the agent with tools."""
        self.llm_with_tools = self.llm_engine.bind_tools(self.tools)
        print(f"âœ… Agent initialized with {len(self.tools)} tools:")
        for tool in self.tools:
            print(f"   - {tool.name}: {tool.description[:40]}...")
    
    async def chat(self, message: str) -> str:
        """Send a message and get a response with auto-retry and search fallback."""
        if not self.llm_with_tools:
            await self.initialize()
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ Linux ç³»ç»Ÿç®¡ç†åŠ©æ‰‹ï¼Œå…·å¤‡è‡ªä¸»å­¦ä¹ å’Œé—®é¢˜è§£å†³èƒ½åŠ›ã€‚

## å¯ç”¨å·¥å…·
- get_system_stats: è·å– CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µ
- get_cpu_info: è·å–è¯¦ç»† CPU ä¿¡æ¯
- get_memory_info: è·å–è¯¦ç»†å†…å­˜ä¿¡æ¯
- get_disk_info: è·å–ç£ç›˜ä¿¡æ¯
- list_services: åˆ—å‡ºç³»ç»ŸæœåŠ¡
- web_search: æœç´¢äº’è”ç½‘è·å–ä¿¡æ¯ã€æ•™ç¨‹ã€æ–‡æ¡£
- fetch_webpage: è·å–ç½‘é¡µè¯¦ç»†å†…å®¹
- run_command: æ‰§è¡Œ Linux å‘½ä»¤

## å·¥ä½œç­–ç•¥
1. é¦–å…ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿå·¥å…·æˆ–å‘½ä»¤è§£å†³é—®é¢˜
2. å¦‚æœé‡åˆ°é”™è¯¯æˆ–ä¸ç¡®å®šå¦‚ä½•æ“ä½œï¼Œä½¿ç”¨ web_search æœç´¢è§£å†³æ–¹æ¡ˆ
3. æ‰¾åˆ°ç›¸å…³æ–‡æ¡£åï¼Œä½¿ç”¨ fetch_webpage è·å–è¯¦ç»†å†…å®¹
4. æ ¹æ®æœç´¢åˆ°çš„ä¿¡æ¯é‡æ–°å°è¯•è§£å†³é—®é¢˜
5. å§‹ç»ˆå‘ç”¨æˆ·è§£é‡Šä½ çš„æ€è€ƒè¿‡ç¨‹å’Œé‡‡å–çš„è¡ŒåŠ¨

## é”™è¯¯å¤„ç†
- å¦‚æœå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œåˆ†æé”™è¯¯ä¿¡æ¯
- æœç´¢é”™è¯¯ä¿¡æ¯ä»¥æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
- å°è¯•ä¸åŒçš„æ–¹æ³•ï¼Œæœ€å¤šé‡è¯• 3 æ¬¡
- å¦‚æœä»ç„¶å¤±è´¥ï¼Œå‘ç”¨æˆ·è§£é‡ŠåŸå› å¹¶æä¾›å»ºè®®"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=message)
        ]
        
        max_iterations = 10
        error_count = 0
        last_error = None
        attempted_solutions = []
        
        for iteration in range(max_iterations):
            # Call LLM
            response = await self.llm_with_tools.ainvoke(messages)
            messages.append(response)
            
            # Check for tool calls
            if not response.tool_calls:
                return response.content
            
            # Execute tool calls
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]
                
                print(f"   ğŸ”§ [{iteration+1}] Calling: {tool_name}")
                if tool_args:
                    args_preview = str(tool_args)[:50]
                    print(f"      Args: {args_preview}...")
                
                # Execute the tool
                result = await execute_tool(tool_name, tool_args)
                
                # Check if result is an error
                try:
                    result_data = json.loads(result)
                    is_error = result_data.get("error", False)
                except:
                    is_error = False
                
                if is_error:
                    error_count += 1
                    last_error = result
                    print(f"   âŒ Error #{error_count}: {result_data.get('message', 'Unknown')[:60]}")
                    
                    # If we've had multiple errors, suggest searching
                    if error_count >= self.max_retries and tool_name not in ["web_search", "fetch_webpage"]:
                        # Add a hint to search for solutions
                        search_hint = f"""
æ“ä½œå¤±è´¥äº† {error_count} æ¬¡ã€‚é”™è¯¯ä¿¡æ¯: {result_data.get('message', 'Unknown')}

è¯·ä½¿ç”¨ web_search å·¥å…·æœç´¢è¿™ä¸ªé”™è¯¯çš„è§£å†³æ–¹æ¡ˆï¼Œæˆ–è€…æœç´¢ç›¸å…³çš„å®˜æ–¹æ–‡æ¡£æ¥æ‰¾åˆ°æ­£ç¡®çš„æ–¹æ³•ã€‚
ä¹‹å‰å°è¯•è¿‡çš„æ–¹æ¡ˆ: {attempted_solutions}
"""
                        messages.append(ToolMessage(content=result, tool_call_id=tool_id))
                        messages.append(HumanMessage(content=search_hint))
                        continue
                else:
                    # Success - reset error count
                    if error_count > 0:
                        print(f"   âœ… Success after {error_count} retries!")
                    error_count = 0
                    
                    # Track what we tried
                    if tool_name == "run_command":
                        attempted_solutions.append(tool_args.get("command", ""))
                
                messages.append(ToolMessage(content=result, tool_call_id=tool_id))
        
        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„è¯·æ±‚æˆ–åˆ†æ­¥éª¤æ‰§è¡Œã€‚"
    
    async def run_interactive(self) -> None:
        """Run in interactive mode."""
        await self.initialize()
        
        print("\n" + "=" * 60)
        print("ğŸ¤– Linux Agent - æ™ºèƒ½åŠ©æ‰‹æ¨¡å¼")
        print("=" * 60)
        print("ç‰¹æ€§: è‡ªåŠ¨é‡è¯• + æœç´¢å›é€€ + æ–‡æ¡£æŸ¥é˜…")
        print("è¾“å…¥ 'quit' é€€å‡º, 'help' æŸ¥çœ‹å¸®åŠ©")
        print("-" * 60 + "\n")
        
        while True:
            try:
                user_input = input("You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ("quit", "exit"):
                    print("\nGoodbye! ğŸ‘‹")
                    break
                
                if user_input.lower() == "help":
                    print("""
å¯ç”¨å‘½ä»¤ç¤ºä¾‹:
  - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  - æ£€æŸ¥ nginx æœåŠ¡çŠ¶æ€
  - æœç´¢ Docker å®‰è£…æ•™ç¨‹
  - æ‰§è¡Œ df -h å‘½ä»¤
  - å¦‚ä½•é…ç½® SSH å…å¯†ç™»å½•
""")
                    continue
                
                print("\nğŸ¤” Thinking...\n")
                response = await self.chat(user_input)
                print(f"\nAgent: {response}\n")
                
            except KeyboardInterrupt:
                print("\n\nInterrupted. Type 'quit' to exit.\n")
            except EOFError:
                print("\nGoodbye! ğŸ‘‹")
                break


async def main():
    """Main entry point."""
    import os
    import sys
    
    # Get API key from environment
    api_key = os.environ.get("DEEPSEEK_API_KEY", "")
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")
        provider = "openai"
        model = "gpt-4o"
    else:
        provider = "deepseek"
        model = "deepseek-chat"
    
    if not api_key:
        print("Error: Please set DEEPSEEK_API_KEY or OPENAI_API_KEY")
        sys.exit(1)
    
    agent = SimpleLinuxAgent(
        llm_provider=provider,
        llm_model=model,
        api_key=api_key,
        max_retries=3
    )
    
    await agent.run_interactive()


if __name__ == "__main__":
    asyncio.run(main())
