"""Web interface for Multi-AI Linux Agent with streaming support."""

import asyncio
import json
from dataclasses import dataclass, field
from typing import Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse

from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage, AIMessageChunk

from .orchestrator.llm_engine import create_llm_engine, LLMEngine
from .tools import execute_tool, get_all_tools
from .multi_agent import AIConfig, load_config_from_file, load_config_from_env
from .prompts import get_prompt
from .experience_rag import get_experience_rag

app = FastAPI(title="Linux AI Agent")


class StreamingWebAgent:
    """Agent with streaming output support and task-oriented completion."""
    
    def __init__(self, websocket: WebSocket):
        self.ws = websocket
        self.primary_engine = None
        self.secondary_engines = {}
        self.tools = get_all_tools()
        self.primary_llm = None
        
        # æŒä¹…åŒ–å¯¹è¯å†å²
        self.messages = []
        self.initialized = False
        
        # ä»»åŠ¡æ§åˆ¶
        self.should_stop = False
        
        # RAG ç»éªŒç³»ç»Ÿ
        self.experience_rag = None
    
    async def send_event(self, event_type: str, data: dict):
        """Send event to frontend."""
        try:
            await self.ws.send_json({"type": event_type, **data})
        except:
            pass
    
    async def initialize(self):
        """Initialize AI engines from config."""
        if self.initialized:
            return True
            
        config = load_config_from_file()
        
        if config:
            primary = AIConfig(
                name=config.primary_ai.name,
                provider=config.primary_ai.provider,
                model=config.primary_ai.model,
                api_key=config.primary_ai.api_key,
                role="primary",
                base_url=config.primary_ai.base_url
            )
            secondary_list = [
                AIConfig(name=ai.name, provider=ai.provider, model=ai.model,
                        api_key=ai.api_key, role=ai.role, base_url=ai.base_url)
                for ai in config.secondary_ais
            ]
            self.max_retries = config.agent.max_retries
            self.search_before_consult = config.agent.search_attempts_before_consult
        else:
            primary, secondary_list = load_config_from_env()
            self.max_retries = 3
            self.search_before_consult = 2
        
        if not primary or not primary.api_key:
            await self.send_event("error", {"message": "No API key configured"})
            return False
        
        # Initialize primary with streaming enabled
        kwargs = {}
        if primary.base_url:
            kwargs['base_url'] = primary.base_url
        
        self.primary_engine = create_llm_engine(
            provider=primary.provider, model=primary.model, api_key=primary.api_key,
            **kwargs
        )
        self.primary_llm = self.primary_engine.bind_tools(self.tools)
        
        await self.send_event("status", {
            "message": f"âœ… Primary AI: {primary.name} ({primary.model})"
        })
        
        # Initialize secondary
        for cfg in (secondary_list or []):
            kwargs = {}
            if cfg.base_url:
                kwargs['base_url'] = cfg.base_url
            engine = create_llm_engine(provider=cfg.provider, model=cfg.model, api_key=cfg.api_key, **kwargs)
            self.secondary_engines[cfg.name] = {"engine": engine, "config": cfg}
            await self.send_event("status", {
                "message": f"âœ… Secondary AI: {cfg.name} ({cfg.model})"
            })
        
        # åˆå§‹åŒ–ç³»ç»Ÿæç¤º - ä½¿ç”¨æ–°çš„æç¤ºè¯ç³»ç»Ÿ
        base_prompt = get_prompt("default")
        
        task_completion_instructions = """

## ä»»åŠ¡å®Œæˆæœºåˆ¶

åœ¨æœ€ç»ˆå›å¤æœ«å°¾æ ‡æ³¨çŠ¶æ€ï¼š
- `[STATUS: COMPLETED]` - ä»»åŠ¡å·²å®Œæˆ
- `[STATUS: NEEDS_INPUT]` - éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯
- `[STATUS: FAILED: åŸå› ]` - ä»»åŠ¡å¤±è´¥

### æ ¸å¿ƒåŸåˆ™
1. **æŒç»­å·¥ä½œç›´åˆ°å®Œæˆ**: ä¸è¦ä¸­é€”åœæ­¢
2. **é‡åˆ°å›°éš¾ä¼˜å…ˆæŸ¥å®˜æ–¹æ–‡æ¡£**: æœç´¢ "[è½¯ä»¶å] official documentation [é—®é¢˜]"
3. **å†™ä»£ç æ—¶**: å…ˆåˆ›å»ºç›®å½•ï¼Œå†é€ä¸ªåˆ›å»ºå®Œæ•´æ–‡ä»¶
"""
        
        system_prompt = base_prompt + task_completion_instructions

        self.messages = [SystemMessage(content=system_prompt)]
        self.initialized = True
        
        # åˆå§‹åŒ– RAG ç»éªŒç³»ç»Ÿ
        try:
            self.experience_rag = get_experience_rag()
            stats = self.experience_rag.get_stats()
            await self.send_event("status", {"message": f"ğŸ“š RAG: {stats.get('total_experiences', 0)} experiences"})
        except Exception as e:
            await self.send_event("status", {"message": f"âš ï¸ RAG init failed: {e}"})
        
        await self.send_event("status", {"message": f"âœ… Loaded {len(self.tools)} tools"})
        return True
    
    def stop_current_task(self):
        """Stop the current running task."""
        self.should_stop = True
    
    async def stream_response(self, iteration: int):
        """Stream LLM response token by token."""
        full_content = ""
        tool_calls = []
        tool_call_chunks = {}
        
        await self.send_event("stream_start", {"iteration": iteration})
        
        try:
            async for chunk in self.primary_llm.astream(self.messages):
                if self.should_stop:
                    break
                
                # å¤„ç†æ–‡æœ¬å†…å®¹ - å…¼å®¹ä¸åŒæ ¼å¼
                if chunk.content:
                    content_text = ""
                    if isinstance(chunk.content, str):
                        content_text = chunk.content
                    elif isinstance(chunk.content, list):
                        # Gemini å¯èƒ½è¿”å› list æ ¼å¼
                        for item in chunk.content:
                            if isinstance(item, str):
                                content_text += item
                            elif isinstance(item, dict) and item.get('text'):
                                content_text += item['text']
                    
                    if content_text:
                        full_content += content_text
                        await self.send_event("stream_token", {"token": content_text})
                
                # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆæµå¼ï¼‰- ä½¿ç”¨ tool_call_chunks å±æ€§
                if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:
                    for tc_chunk in chunk.tool_call_chunks:
                        idx = tc_chunk.get('index', 0)
                        if idx not in tool_call_chunks:
                            tool_call_chunks[idx] = {
                                'id': '',
                                'name': '',
                                'args': ''
                            }
                        
                        if tc_chunk.get('id'):
                            tool_call_chunks[idx]['id'] = tc_chunk['id']
                        if tc_chunk.get('name'):
                            tool_call_chunks[idx]['name'] = tc_chunk['name']
                        if tc_chunk.get('args'):
                            tool_call_chunks[idx]['args'] += tc_chunk['args']
                            # æµå¼æ˜¾ç¤ºå·¥å…·å‚æ•°
                            await self.send_event("stream_tool_arg", {
                                "index": idx,
                                "name": tool_call_chunks[idx]['name'],
                                "arg_chunk": tc_chunk['args']
                            })
                
                # æœ‰äº›æ¨¡å‹ç›´æ¥è¿”å›å®Œæ•´çš„ tool_calls
                if hasattr(chunk, 'tool_calls') and chunk.tool_calls:
                    for tc in chunk.tool_calls:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼ˆæœ‰ name å’Œ argsï¼‰
                        if isinstance(tc, dict) and tc.get('name') and 'args' in tc:
                            tool_calls.append(tc)
            
            # ä» chunks ç»„è£…å·¥å…·è°ƒç”¨
            for idx in sorted(tool_call_chunks.keys()):
                tc = tool_call_chunks[idx]
                if tc['name'] and tc['args']:
                    try:
                        args = json.loads(tc['args'])
                    except json.JSONDecodeError:
                        # å‚æ•°è§£æå¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªå·¥å…·è°ƒç”¨
                        await self.send_event("status", {"message": f"âš ï¸ å·¥å…·å‚æ•°è§£æå¤±è´¥: {tc['name']}"})
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„å·¥å…·è°ƒç”¨
                    exists = any(
                        t.get('name') == tc['name'] and t.get('args') == args 
                        for t in tool_calls
                    )
                    if not exists:
                        tool_calls.append({
                            'id': tc['id'] or f"call_{idx}",
                            'name': tc['name'],
                            'args': args
                        })
            
            await self.send_event("stream_end", {})
            
            # æ„å»º AI æ¶ˆæ¯
            if tool_calls:
                response = AIMessage(content=full_content, tool_calls=tool_calls)
            else:
                response = AIMessage(content=full_content)
            
            return response
            
        except Exception as e:
            await self.send_event("error", {"message": f"Stream error: {str(e)}"})
            return None
    
    async def chat(self, message: str):
        """Process message with task-oriented completion and RAG support."""
        if not await self.initialize():
            return
        
        self.should_stop = False
        
        # RAG: æ£€ç´¢ç›¸å…³ç»éªŒ
        if self.experience_rag:
            try:
                similar = self.experience_rag.search_similar(message, top_k=2)
                if similar:
                    exp_context = self.experience_rag.format_experiences_for_prompt(similar)
                    await self.send_event("status", {"message": f"ğŸ“š Found {len(similar)} relevant experiences"})
                    # å°†ç»éªŒä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ 
                    self.messages.append(SystemMessage(content=exp_context))
            except Exception as e:
                await self.send_event("status", {"message": f"âš ï¸ RAG search failed: {e}"})
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.messages.append(HumanMessage(content=message))
        
        # è¿½è¸ªçŠ¶æ€ï¼ˆç”¨äºä¿å­˜ç»éªŒï¼‰
        all_steps = []
        tools_used = []
        errors = []
        docs_consulted = []
        error_tracker = {}
        consecutive_no_progress = 0
        
        while True:  # ä»»åŠ¡å¯¼å‘å¾ªç¯ï¼Œä¸é™åˆ¶è¿­ä»£æ¬¡æ•°
            if self.should_stop:
                await self.send_event("stopped", {"message": "ä»»åŠ¡å·²ä¸­æ–­"})
                return
            
            try:
                await self.send_event("thinking", {"iteration": len(all_steps) + 1})
                
                # æµå¼è·å–å“åº”
                full_content = ""
                tool_call_chunks = {}
                chunk_count = 0
                
                await self.send_event("stream_start", {})
                
                try:
                    # è®¾ç½®æœ€å¤§ chunk æ•°é‡é™åˆ¶ï¼Œé˜²æ­¢æ— é™ç”Ÿæˆ
                    MAX_CHUNKS = 5000
                    STREAM_TIMEOUT = 180  # æµå¼å“åº”æœ€å¤§ 180 ç§’
                    stream_start_time = asyncio.get_event_loop().time()
                    forced_stop = False  # æ ‡è®°æ˜¯å¦å¼ºåˆ¶åœæ­¢
                    
                    async for chunk in self.primary_llm.astream(self.messages):
                        if self.should_stop:
                            break
                        
                        chunk_count += 1
                        
                        # è¶…è¿‡æœ€å¤§ chunk æ•°é‡ï¼Œå¼ºåˆ¶åœæ­¢
                        if chunk_count >= MAX_CHUNKS:
                            await self.send_event("status", {"message": f"âš ï¸ è¾¾åˆ°æœ€å¤§ chunk é™åˆ¶ ({MAX_CHUNKS})ï¼Œå¼ºåˆ¶ç»“æŸ"})
                            forced_stop = True
                            break
                        
                        # è¶…æ—¶æ£€æŸ¥
                        elapsed = asyncio.get_event_loop().time() - stream_start_time
                        if elapsed > STREAM_TIMEOUT:
                            await self.send_event("status", {"message": f"âš ï¸ æµå¼å“åº”è¶…æ—¶ ({STREAM_TIMEOUT}s)ï¼Œå¼ºåˆ¶ç»“æŸ"})
                            forced_stop = True
                            break
                        
                        if chunk_count % 100 == 0:
                            # æ˜¾ç¤ºå½“å‰ç”Ÿæˆçš„å†…å®¹é¢„è§ˆ
                            preview = full_content[-200:] if len(full_content) > 200 else full_content
                            preview = preview.replace('\n', ' ')[:100]  # å•è¡Œé¢„è§ˆ
                            await self.send_event("status", {"message": f"ğŸ“¦ {chunk_count} chunks | é¢„è§ˆ: {preview}..."})
                        
                        # å¤„ç†æ–‡æœ¬å†…å®¹
                        if chunk.content:
                            text = ""
                            if isinstance(chunk.content, str):
                                text = chunk.content
                            elif isinstance(chunk.content, list):
                                for item in chunk.content:
                                    if isinstance(item, str):
                                        text += item
                                    elif isinstance(item, dict) and item.get('text'):
                                        text += item['text']
                            
                            if text:
                                full_content += text
                                await self.send_event("stream_token", {"token": text})
                        
                        # ç´¯ç§¯å·¥å…·è°ƒç”¨ chunks
                        if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:
                            for tc_chunk in chunk.tool_call_chunks:
                                idx = tc_chunk.get('index', 0)
                                if idx not in tool_call_chunks:
                                    tool_call_chunks[idx] = {'id': '', 'name': '', 'args': ''}
                                
                                if tc_chunk.get('id'):
                                    tool_call_chunks[idx]['id'] = tc_chunk['id']
                                if tc_chunk.get('name'):
                                    tool_call_chunks[idx]['name'] = tc_chunk['name']
                                    await self.send_event("status", {"message": f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·: {tc_chunk['name']}"})
                                if tc_chunk.get('args'):
                                    tool_call_chunks[idx]['args'] += tc_chunk['args']
                        
                        if hasattr(chunk, 'tool_calls') and chunk.tool_calls:
                            for i, tc in enumerate(chunk.tool_calls):
                                if isinstance(tc, dict) and tc.get('name') and tc.get('args'):
                                    idx = tc.get('index', i)
                                    tool_call_chunks[idx] = {
                                        'id': tc.get('id', f'call_{idx}'),
                                        'name': tc['name'],
                                        'args': json.dumps(tc['args']) if isinstance(tc['args'], dict) else tc['args']
                                    }
                                    await self.send_event("status", {"message": f"ğŸ”§ å·¥å…·è°ƒç”¨: {tc['name']}"})
                
                except asyncio.TimeoutError:
                    await self.send_event("error", {"message": "æµå¼å“åº”è¶…æ—¶"})
                    return
                
                await self.send_event("stream_end", {"chunks": chunk_count})
                
                # è§£æå·¥å…·è°ƒç”¨
                tool_calls = []
                for idx in sorted(tool_call_chunks.keys()):
                    tc = tool_call_chunks[idx]
                    if tc['name']:
                        try:
                            args = json.loads(tc['args']) if tc['args'] else {}
                        except json.JSONDecodeError:
                            args = {}
                        
                        if args or tc['name'] in ['get_system_stats', 'get_cpu_info', 'get_memory_info', 'get_disk_info']:
                            tool_calls.append({
                                'id': tc['id'] or f'call_{idx}',
                                'name': tc['name'],
                                'args': args
                            })
                
                # æ„å»ºå“åº”æ¶ˆæ¯
                if tool_calls:
                    response = AIMessage(content=full_content, tool_calls=tool_calls)
                else:
                    response = AIMessage(content=full_content)
                
                self.messages.append(response)
                
                # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                if not tool_calls:
                    # å¦‚æœæ˜¯å¼ºåˆ¶åœæ­¢ï¼Œç›´æ¥è¿”å›å·²ç”Ÿæˆçš„å†…å®¹
                    if forced_stop:
                        await self.send_event("response", {"content": full_content + "\n\nâš ï¸ (å†…å®¹ç”Ÿæˆè¢«æˆªæ–­)"})
                        return
                    
                    # è§£æçŠ¶æ€
                    content_lower = full_content.lower()
                    task_completed = "[status: completed]" in content_lower
                    task_failed = "[status: failed" in content_lower
                    needs_input = "[status: needs_input]" in content_lower
                    
                    clean_content = full_content
                    for tag in ["[STATUS: COMPLETED]", "[STATUS: NEEDS_INPUT]", "[STATUS: IN_PROGRESS]"]:
                        clean_content = clean_content.replace(tag, "").strip()
                    
                    if task_completed or task_failed:
                        # ä¿å­˜ç»éªŒ
                        if self.experience_rag:
                            try:
                                self.experience_rag.save_experience(
                                    problem=message,
                                    solution=clean_content[:500],
                                    steps=all_steps[-10:],
                                    tools_used=tools_used,
                                    errors_encountered=errors[-5:],
                                    docs_consulted=docs_consulted[-5:],
                                    success=task_completed
                                )
                                await self.send_event("status", {"message": "ğŸ’¾ Experience saved"})
                            except:
                                pass
                        
                        await self.send_event("response", {"content": clean_content})
                        return
                    elif needs_input:
                        await self.send_event("response", {"content": clean_content})
                        return
                    else:
                        # æ²¡æœ‰æ˜ç¡®çŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦å¡ä½
                        consecutive_no_progress += 1
                        if consecutive_no_progress >= 2:
                            await self.send_event("response", {"content": full_content})
                            return
                        # æé†’æ ‡è®°çŠ¶æ€
                        self.messages.append(HumanMessage(
                            content="è¯·ç¡®è®¤ä»»åŠ¡æ˜¯å¦å®Œæˆï¼Œå¹¶æ ‡æ³¨ [STATUS: COMPLETED] æˆ–ç»§ç»­æ‰§è¡Œã€‚"
                        ))
                        continue
                
                consecutive_no_progress = 0
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    if self.should_stop:
                        await self.send_event("stopped", {"message": "ä»»åŠ¡å·²ä¸­æ–­"})
                        return
                    
                    tool_name = tool_call['name']
                    tool_args = tool_call['args']
                    tool_id = tool_call['id']
                    
                    # è®°å½•æ­¥éª¤
                    step_desc = f"{tool_name}: {str(tool_args)[:80]}"
                    all_steps.append(step_desc)
                    if tool_name not in tools_used:
                        tools_used.append(tool_name)
                    
                    if tool_name == "fetch_webpage":
                        docs_consulted.append(tool_args.get("url", ""))
                    
                    await self.send_event("tool_call", {
                        "name": tool_name,
                        "args": tool_args,
                        "iteration": len(all_steps)
                    })
                    
                    try:
                        result = await asyncio.wait_for(
                            execute_tool(tool_name, tool_args),
                            timeout=120
                        )
                    except asyncio.TimeoutError:
                        result = json.dumps({"error": True, "message": "Tool execution timed out"})
                    
                    try:
                        result_data = json.loads(result)
                        is_error = result_data.get("error", False)
                        error_msg = result_data.get("message", "")
                    except:
                        is_error = False
                        error_msg = ""
                    
                    await self.send_event("tool_result", {
                        "name": tool_name,
                        "result": result[:3000],
                        "is_error": is_error
                    })
                    
                    if is_error:
                        errors.append(error_msg)
                        error_key = f"{tool_name}:{error_msg[:50]}"
                        error_tracker[error_key] = error_tracker.get(error_key, 0) + 1
                        
                        # é‡å¤é”™è¯¯æç¤ºæŸ¥å®˜æ–¹æ–‡æ¡£
                        if error_tracker[error_key] >= 3:
                            hint = f"""
è¿™ä¸ªé”™è¯¯å·²å‡ºç° {error_tracker[error_key]} æ¬¡: {error_msg}

è¯·ä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£:
1. web_search æœç´¢ "[è½¯ä»¶å] official documentation [é”™è¯¯å…³é”®è¯]"
2. fetch_webpage è·å–æ–‡æ¡£å†…å®¹
3. æŒ‰å®˜æ–¹æŒ‡å¯¼æ“ä½œ
"""
                            self.messages.append(ToolMessage(content=result, tool_call_id=tool_id))
                            self.messages.append(HumanMessage(content=hint))
                            continue
                    
                    # ç®€åŒ–å†™æ–‡ä»¶ç»“æœ
                    if tool_name == "write_file" and not is_error:
                        try:
                            simplified = {"success": True, "path": result_data.get("path"), "size": result_data.get("size")}
                            result_for_history = json.dumps(simplified, ensure_ascii=False)
                        except:
                            result_for_history = result[:1000]
                    else:
                        result_for_history = result[:5000] if len(result) > 5000 else result
                    
                    self.messages.append(ToolMessage(content=result_for_history, tool_call_id=tool_id))
                    
            except Exception as e:
                await self.send_event("error", {"message": f"é”™è¯¯: {str(e)}"})
                import traceback
                traceback.print_exc()
                return
    
    async def clear_history(self):
        """Clear conversation history but keep system prompt."""
        if self.messages:
            self.messages = self.messages[:1]
        await self.send_event("cleared", {"message": "å¯¹è¯å†å²å·²æ¸…é™¤"})


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for chat."""
    await websocket.accept()
    agent = StreamingWebAgent(websocket)
    current_task = None
    
    try:
        while True:
            data = await websocket.receive_json()
            msg_type = data.get("type")
            
            if msg_type == "chat":
                if current_task and not current_task.done():
                    agent.stop_current_task()
                    await asyncio.sleep(0.1)
                
                agent.should_stop = False
                current_task = asyncio.create_task(agent.chat(data.get("message", "")))
            elif msg_type == "stop":
                agent.stop_current_task()
            elif msg_type == "clear":
                await agent.clear_history()
                
    except WebSocketDisconnect:
        if current_task:
            agent.stop_current_task()


@app.get("/")
async def get_index():
    return HTMLResponse(HTML_CONTENT)


HTML_CONTENT = '''
<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linux AI Agent</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a2e;
            color: #eee;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .header {
            background: #16213e;
            padding: 12px 20px;
            border-bottom: 1px solid #0f3460;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }
        .header h1 { font-size: 1.2em; color: #00d9ff; display: flex; align-items: center; gap: 10px; }
        .header-btns { display: flex; gap: 10px; }
        .header-btns button {
            padding: 6px 12px;
            border: 1px solid #444;
            border-radius: 5px;
            background: transparent;
            color: #aaa;
            cursor: pointer;
            font-size: 0.85em;
        }
        .header-btns button:hover { background: #333; color: #fff; }
        .main { flex: 1; display: flex; overflow: hidden; }
        .chat-panel { flex: 1; display: flex; flex-direction: column; }
        .log-panel {
            width: 500px;
            display: flex;
            flex-direction: column;
            background: #0f0f1a;
            border-left: 1px solid #0f3460;
        }
        .panel-header {
            padding: 10px 15px;
            background: #16213e;
            font-weight: 600;
            font-size: 0.85em;
            color: #888;
            display: flex;
            justify-content: space-between;
        }
        .messages { flex: 1; overflow-y: auto; padding: 15px; }
        .message {
            margin-bottom: 12px;
            padding: 10px 14px;
            border-radius: 8px;
            max-width: 90%;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .message.user { background: #0f3460; margin-left: auto; }
        .message.assistant { background: #1e1e30; border: 1px solid #333; }
        .message.system { background: #2a2a3a; color: #888; font-size: 0.9em; text-align: center; max-width: 100%; }
        .message.streaming { border: 1px solid #00d9ff; }
        .input-area {
            padding: 12px 15px;
            background: #16213e;
            display: flex;
            gap: 10px;
        }
        input[type="text"] {
            flex: 1;
            padding: 10px 14px;
            border: none;
            border-radius: 6px;
            background: #1a1a2e;
            color: #fff;
            font-size: 0.95em;
        }
        input[type="text"]:focus { outline: 2px solid #00d9ff; }
        .input-area button {
            padding: 10px 20px;
            border: none;
            border-radius: 6px;
            font-weight: 600;
            cursor: pointer;
        }
        .btn-send { background: #00d9ff; color: #000; }
        .btn-stop { background: #ff4757; color: #fff; }
        .logs {
            flex: 1;
            overflow-y: auto;
            padding: 8px;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.75em;
        }
        .log-entry {
            padding: 6px 8px;
            margin-bottom: 4px;
            border-radius: 4px;
            background: #1a1a2e;
        }
        .log-entry.tool { border-left: 3px solid #ffd700; }
        .log-entry.result { border-left: 3px solid #00ff88; }
        .log-entry.error { border-left: 3px solid #ff4444; }
        .log-entry.status { border-left: 3px solid #00d9ff; color: #888; }
        .log-entry.stream { border-left: 3px solid #aa88ff; background: #1a1a30; }
        .log-entry.stream .log-content { 
            max-height: 400px; 
            font-size: 0.8em;
            line-height: 1.4;
        }
        .log-label { font-weight: 600; margin-bottom: 3px; }
        .log-content {
            color: #aaa;
            white-space: pre-wrap;
            word-break: break-all;
            max-height: 200px;
            overflow-y: auto;
        }
        .status-dot { width: 8px; height: 8px; border-radius: 50%; background: #555; }
        .status-dot.connected { background: #00ff88; }
        .status-dot.working { background: #ffd700; animation: pulse 1s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.4; } }
        .stream-content { color: #00d9ff; font-family: monospace; }
        .cursor { animation: blink 1s infinite; }
        @keyframes blink { 0%, 50% { opacity: 1; } 51%, 100% { opacity: 0; } }
        /* Markdown æ ·å¼ */
        .message.assistant h1, .message.assistant h2, .message.assistant h3 { 
            margin: 12px 0 8px 0; color: #00d9ff; 
        }
        .message.assistant h1 { font-size: 1.4em; }
        .message.assistant h2 { font-size: 1.2em; }
        .message.assistant h3 { font-size: 1.1em; }
        .message.assistant ul, .message.assistant ol { margin: 8px 0; padding-left: 20px; }
        .message.assistant li { margin: 4px 0; }
        .message.assistant code { 
            background: #2a2a3a; padding: 2px 6px; border-radius: 4px; 
            font-family: 'Monaco', 'Consolas', monospace; font-size: 0.9em;
        }
        .message.assistant pre { 
            background: #1a1a2e; padding: 12px; border-radius: 6px; 
            overflow-x: auto; margin: 10px 0;
        }
        .message.assistant pre code { background: none; padding: 0; }
        .message.assistant table { border-collapse: collapse; margin: 10px 0; width: 100%; }
        .message.assistant th, .message.assistant td { 
            border: 1px solid #444; padding: 8px; text-align: left; 
        }
        .message.assistant th { background: #2a2a3a; }
        .message.assistant blockquote { 
            border-left: 3px solid #00d9ff; margin: 10px 0; padding-left: 12px; color: #aaa; 
        }
        .message.assistant hr { border: none; border-top: 1px solid #444; margin: 15px 0; }
        .message.assistant strong { color: #fff; }
        .message.assistant a { color: #00d9ff; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        // ç¡®ä¿ marked åŠ è½½å®Œæˆ
        if (typeof marked !== 'undefined') {
            marked.setOptions({ breaks: true, gfm: true });
        }
    </script>
</head>
<body>
    <div class="header">
        <h1><span class="status-dot" id="status"></span> Linux AI Agent (Streaming)</h1>
        <div class="header-btns">
            <button onclick="clearChat()">æ¸…é™¤å¯¹è¯</button>
            <button onclick="clearLogs()">æ¸…é™¤æ—¥å¿—</button>
        </div>
    </div>
    <div class="main">
        <div class="chat-panel">
            <div class="messages" id="messages"></div>
            <div class="input-area">
                <input type="text" id="input" placeholder="è¾“å…¥æŒ‡ä»¤..." />
                <button class="btn-send" id="sendBtn" onclick="sendMessage()">å‘é€</button>
                <button class="btn-stop" id="stopBtn" onclick="stopTask()" style="display:none;">åœæ­¢</button>
            </div>
        </div>
        <div class="log-panel">
            <div class="panel-header">
                <span>ğŸ“‹ æ‰§è¡Œæ—¥å¿— (å®æ—¶æµ)</span>
                <span id="msgCount">0 æ¡</span>
            </div>
            <div class="logs" id="logs"></div>
        </div>
    </div>
    <script>
        let ws, isWorking = false, msgCount = 0;
        let currentStreamDiv = null, currentStreamContent = '';
        let currentToolStreamDiv = null, currentToolArgs = {};
        
        const messages = document.getElementById('messages');
        const logs = document.getElementById('logs');
        const input = document.getElementById('input');
        const sendBtn = document.getElementById('sendBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');

        function connect() {
            ws = new WebSocket(`ws://${location.host}/ws`);
            ws.onopen = () => { status.className = 'status-dot connected'; addLog('status', 'å·²è¿æ¥', ''); };
            ws.onclose = () => { status.className = 'status-dot'; setTimeout(connect, 2000); };
            ws.onmessage = (e) => handleEvent(JSON.parse(e.data));
        }

        function setWorking(working) {
            isWorking = working;
            status.className = working ? 'status-dot working' : 'status-dot connected';
            sendBtn.style.display = working ? 'none' : 'block';
            stopBtn.style.display = working ? 'block' : 'none';
        }

        function handleEvent(event) {
            switch(event.type) {
                case 'status':
                    addLog('status', 'çŠ¶æ€', event.message);
                    break;
                case 'thinking':
                    setWorking(true);
                    addLog('status', `ğŸ¤” è¿­ä»£ #${event.iteration}`, 'æ€è€ƒä¸­...');
                    break;
                case 'ai_text':
                    addLog('status', 'ğŸ’­ AI', event.content);
                    break;
                case 'stream_start':
                    currentStreamContent = '';
                    currentStreamDiv = document.createElement('div');
                    currentStreamDiv.className = 'log-entry stream';
                    currentStreamDiv.innerHTML = '<div class="log-label">ğŸ“ AI ç”Ÿæˆä¸­...</div><div class="log-content stream-content"></div>';
                    logs.appendChild(currentStreamDiv);
                    break;
                case 'stream_token':
                    if (currentStreamDiv) {
                        currentStreamContent += event.token;
                        const contentDiv = currentStreamDiv.querySelector('.stream-content');
                        // æ˜¾ç¤ºæœ€å 800 å­—ç¬¦ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æ›´å¤šå†…å®¹
                        contentDiv.textContent = currentStreamContent.slice(-800) + 'â–Œ';
                        logs.scrollTop = logs.scrollHeight;
                    }
                    break;
                case 'stream_end':
                    if (currentStreamDiv) {
                        const contentDiv = currentStreamDiv.querySelector('.stream-content');
                        const info = event.chunks ? ` (${event.chunks} chunks)` : '';
                        contentDiv.textContent = currentStreamContent ? currentStreamContent.slice(-300) + info : '(è°ƒç”¨å·¥å…·ä¸­...)';
                    }
                    currentStreamDiv = null;
                    break;
                case 'tool_call':
                    addLog('tool', `ğŸ”§ ${event.name}`, JSON.stringify(event.args, null, 2));
                    break;
                case 'tool_result':
                    addLog(event.is_error ? 'error' : 'result', 
                           event.is_error ? 'âŒ é”™è¯¯' : 'âœ… ç»“æœ', event.result);
                    break;
                case 'response':
                    setWorking(false);
                    addMessage('assistant', event.content);
                    break;
                case 'stopped':
                    setWorking(false);
                    addLog('status', 'â¹ï¸ å·²åœæ­¢', event.message);
                    break;
                case 'cleared':
                    addMessage('system', event.message);
                    break;
                case 'error':
                    setWorking(false);
                    addLog('error', 'âŒ é”™è¯¯', event.message);
                    break;
            }
        }

        function addMessage(role, content) {
            msgCount++;
            document.getElementById('msgCount').textContent = `${msgCount} æ¡`;
            const div = document.createElement('div');
            div.className = `message ${role}`;
            // AI å›å¤ç”¨ Markdown æ¸²æŸ“
            if (role === 'assistant') {
                if (typeof marked !== 'undefined' && marked.parse) {
                    try {
                        div.innerHTML = marked.parse(content);
                    } catch(e) {
                        div.innerHTML = simpleMarkdown(content);
                    }
                } else {
                    div.innerHTML = simpleMarkdown(content);
                }
            } else {
                div.textContent = content;
            }
            messages.appendChild(div);
            messages.scrollTop = messages.scrollHeight;
        }
        
        // ç®€å•çš„ Markdown è§£æå¤‡ç”¨æ–¹æ¡ˆ - ä¸ä½¿ç”¨æ­£åˆ™
        function simpleMarkdown(text) {
            if (!text) return '';
            // ç›´æ¥ç”¨ split/join æ›¿æ¢ï¼Œé¿å…æ­£åˆ™
            var html = String(text);
            html = html.split('&').join('&amp;');
            html = html.split('<').join('&lt;');
            html = html.split('>').join('&gt;');
            html = html.split(String.fromCharCode(10)).join('<br>');
            return html;
        }

        function addLog(type, label, content) {
            const div = document.createElement('div');
            div.className = `log-entry ${type}`;
            div.innerHTML = `<div class="log-label">${label}</div>${content ? `<div class="log-content">${escapeHtml(content)}</div>` : ''}`;
            logs.appendChild(div);
            logs.scrollTop = logs.scrollHeight;
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        function sendMessage() {
            const msg = input.value.trim();
            if (!msg || !ws || ws.readyState !== 1) return;
            addMessage('user', msg);
            ws.send(JSON.stringify({type: 'chat', message: msg}));
            input.value = '';
            setWorking(true);
        }

        function stopTask() {
            if (ws && ws.readyState === 1) ws.send(JSON.stringify({type: 'stop'}));
        }

        function clearChat() {
            if (ws && ws.readyState === 1) ws.send(JSON.stringify({type: 'clear'}));
            messages.innerHTML = '';
            msgCount = 0;
            document.getElementById('msgCount').textContent = '0 æ¡';
        }

        function clearLogs() { logs.innerHTML = ''; }

        input.addEventListener('keypress', (e) => { if (e.key === 'Enter') sendMessage(); });
        connect();
    </script>
</body>
</html>
'''

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
