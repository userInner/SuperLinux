"""RAG-based experience learning system for the agent."""

import json
import os
import hashlib
from datetime import datetime
from typing import Optional
from dataclasses import dataclass, asdict

# ä½¿ç”¨è½»é‡çº§å‘é‡æ•°æ®åº“
try:
    import chromadb
    from chromadb.config import Settings
    HAS_CHROMA = True
except ImportError:
    HAS_CHROMA = False

try:
    from sentence_transformers import SentenceTransformer
    HAS_SENTENCE_TRANSFORMERS = True
except ImportError:
    HAS_SENTENCE_TRANSFORMERS = False


@dataclass
class Experience:
    """ä¸€æ¡ç»éªŒè®°å½•"""
    id: str
    problem: str           # ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    solution: str          # æˆåŠŸçš„è§£å†³æ–¹æ¡ˆ
    steps: list[str]       # æ‰§è¡Œçš„æ­¥éª¤
    tools_used: list[str]  # ä½¿ç”¨çš„å·¥å…·
    errors_encountered: list[str]  # é‡åˆ°çš„é”™è¯¯
    docs_consulted: list[str]      # æŸ¥é˜…çš„æ–‡æ¡£
    success: bool          # æ˜¯å¦æˆåŠŸ
    timestamp: str         # æ—¶é—´æˆ³
    tags: list[str]        # æ ‡ç­¾ï¼ˆç”¨äºåˆ†ç±»ï¼‰


class ExperienceRAG:
    """åŸºäº RAG çš„ç»éªŒå­¦ä¹ ç³»ç»Ÿã€‚
    
    åŠŸèƒ½ï¼š
    1. ä¿å­˜æˆåŠŸè§£å†³é—®é¢˜çš„ç»éªŒ
    2. é‡åˆ°æ–°é—®é¢˜æ—¶æ£€ç´¢ç›¸ä¼¼ç»éªŒ
    3. å°†ç›¸å…³ç»éªŒæ³¨å…¥åˆ° prompt ä¸­
    """
    
    def __init__(
        self,
        db_path: str = "./experience_db",
        embedding_model: str = "all-MiniLM-L6-v2",
        use_local_embedding: bool = True
    ):
        self.db_path = db_path
        self.embedding_model_name = embedding_model
        self.use_local_embedding = use_local_embedding
        
        self.collection = None
        self.embedding_model = None
        self._initialized = False
        
        # ç®€å•çš„ JSON å¤‡ä»½ï¼ˆå½“å‘é‡åº“ä¸å¯ç”¨æ—¶ï¼‰
        self.json_backup_path = os.path.join(db_path, "experiences.json")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ– RAG ç³»ç»Ÿ"""
        os.makedirs(self.db_path, exist_ok=True)
        
        if HAS_CHROMA and HAS_SENTENCE_TRANSFORMERS:
            try:
                # åˆå§‹åŒ– embedding æ¨¡å‹
                print(f"   Loading embedding model: {self.embedding_model_name}...")
                self.embedding_model = SentenceTransformer(self.embedding_model_name)
                
                # åˆå§‹åŒ– ChromaDB
                self.client = chromadb.PersistentClient(
                    path=self.db_path,
                    settings=Settings(anonymized_telemetry=False)
                )
                
                self.collection = self.client.get_or_create_collection(
                    name="agent_experiences",
                    metadata={"description": "Agent problem-solving experiences"}
                )
                
                self._initialized = True
                count = self.collection.count()
                print(f"   âœ… RAG system initialized ({count} experiences)")
                return True
                
            except Exception as e:
                print(f"   âš ï¸ RAG initialization failed: {e}")
                print(f"   Falling back to JSON storage")
                self._initialized = False
                return False
        else:
            missing = []
            if not HAS_CHROMA:
                missing.append("chromadb")
            if not HAS_SENTENCE_TRANSFORMERS:
                missing.append("sentence-transformers")
            print(f"   âš ï¸ Missing packages: {', '.join(missing)}")
            print(f"   Install with: pip install {' '.join(missing)}")
            print(f"   Falling back to JSON storage")
            return False
    
    def _generate_id(self, problem: str) -> str:
        """ç”Ÿæˆç»éªŒ ID"""
        content = f"{problem}{datetime.now().isoformat()}"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    def _extract_tags(self, problem: str, tools_used: list[str]) -> list[str]:
        """ä»é—®é¢˜å’Œå·¥å…·ä¸­æå–æ ‡ç­¾"""
        tags = []
        
        # åŸºäºå…³é”®è¯çš„æ ‡ç­¾
        keywords = {
            "nginx": ["nginx", "web-server", "reverse-proxy"],
            "docker": ["docker", "container"],
            "mysql": ["mysql", "database"],
            "postgresql": ["postgresql", "database"],
            "redis": ["redis", "cache"],
            "ssh": ["ssh", "remote"],
            "systemd": ["systemd", "service"],
            "ç½‘ç»œ": ["network"],
            "ç£ç›˜": ["disk", "storage"],
            "å†…å­˜": ["memory"],
            "cpu": ["cpu", "performance"],
            "python": ["python"],
            "node": ["nodejs"],
            "git": ["git", "version-control"],
        }
        
        problem_lower = problem.lower()
        for keyword, tag_list in keywords.items():
            if keyword in problem_lower:
                tags.extend(tag_list)
        
        # åŸºäºå·¥å…·çš„æ ‡ç­¾
        tool_tags = {
            "run_command": "command",
            "web_search": "search",
            "fetch_webpage": "documentation",
            "read_file": "file-operation",
            "write_file": "file-operation",
            "get_system_stats": "monitoring",
        }
        for tool in tools_used:
            if tool in tool_tags:
                tags.append(tool_tags[tool])
        
        return list(set(tags))
    
    def save_experience(
        self,
        problem: str,
        solution: str,
        steps: list[str],
        tools_used: list[str],
        errors_encountered: list[str] = None,
        docs_consulted: list[str] = None,
        success: bool = True
    ) -> str:
        """ä¿å­˜ä¸€æ¡ç»éªŒ"""
        exp_id = self._generate_id(problem)
        tags = self._extract_tags(problem, tools_used)
        
        experience = Experience(
            id=exp_id,
            problem=problem,
            solution=solution,
            steps=steps,
            tools_used=tools_used,
            errors_encountered=errors_encountered or [],
            docs_consulted=docs_consulted or [],
            success=success,
            timestamp=datetime.now().isoformat(),
            tags=tags
        )
        
        # ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        if self._initialized and self.collection:
            try:
                # ç”Ÿæˆ embedding
                text_to_embed = f"{problem}\n{solution}\n{' '.join(tags)}"
                embedding = self.embedding_model.encode(text_to_embed).tolist()
                
                self.collection.add(
                    ids=[exp_id],
                    embeddings=[embedding],
                    documents=[json.dumps(asdict(experience), ensure_ascii=False)],
                    metadatas=[{
                        "problem": problem[:500],
                        "success": str(success),
                        "tags": ",".join(tags),
                        "timestamp": experience.timestamp
                    }]
                )
                print(f"   ğŸ’¾ Experience saved to vector DB: {exp_id}")
            except Exception as e:
                print(f"   âš ï¸ Failed to save to vector DB: {e}")
        
        # åŒæ—¶ä¿å­˜åˆ° JSON å¤‡ä»½
        self._save_to_json(experience)
        
        return exp_id
    
    def _save_to_json(self, experience: Experience):
        """ä¿å­˜åˆ° JSON æ–‡ä»¶"""
        experiences = []
        if os.path.exists(self.json_backup_path):
            try:
                with open(self.json_backup_path, "r", encoding="utf-8") as f:
                    experiences = json.load(f)
            except:
                experiences = []
        
        experiences.append(asdict(experience))
        
        # åªä¿ç•™æœ€è¿‘ 1000 æ¡
        if len(experiences) > 1000:
            experiences = experiences[-1000:]
        
        os.makedirs(os.path.dirname(self.json_backup_path), exist_ok=True)
        with open(self.json_backup_path, "w", encoding="utf-8") as f:
            json.dump(experiences, f, ensure_ascii=False, indent=2)
    
    def search_similar(
        self,
        query: str,
        top_k: int = 3,
        success_only: bool = True
    ) -> list[Experience]:
        """æœç´¢ç›¸ä¼¼çš„ç»éªŒ"""
        results = []
        
        # ä¼˜å…ˆä½¿ç”¨å‘é‡æœç´¢
        if self._initialized and self.collection:
            try:
                query_embedding = self.embedding_model.encode(query).tolist()
                
                where_filter = {"success": "True"} if success_only else None
                
                search_results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=top_k,
                    where=where_filter
                )
                
                if search_results and search_results["documents"]:
                    for doc in search_results["documents"][0]:
                        try:
                            exp_dict = json.loads(doc)
                            results.append(Experience(**exp_dict))
                        except:
                            continue
                
                return results
            except Exception as e:
                print(f"   âš ï¸ Vector search failed: {e}")
        
        # å›é€€åˆ°ç®€å•çš„å…³é”®è¯æœç´¢
        return self._search_json_fallback(query, top_k, success_only)
    
    def _search_json_fallback(
        self,
        query: str,
        top_k: int,
        success_only: bool
    ) -> list[Experience]:
        """JSON æ–‡ä»¶çš„ç®€å•å…³é”®è¯æœç´¢"""
        if not os.path.exists(self.json_backup_path):
            return []
        
        try:
            with open(self.json_backup_path, "r", encoding="utf-8") as f:
                experiences = json.load(f)
        except:
            return []
        
        query_lower = query.lower()
        query_words = set(query_lower.split())
        
        scored = []
        for exp_dict in experiences:
            if success_only and not exp_dict.get("success", False):
                continue
            
            problem = exp_dict.get("problem", "").lower()
            tags = exp_dict.get("tags", [])
            
            # ç®€å•çš„ç›¸å…³æ€§è¯„åˆ†
            score = 0
            for word in query_words:
                if word in problem:
                    score += 2
                if word in tags:
                    score += 1
            
            if score > 0:
                scored.append((score, Experience(**exp_dict)))
        
        # æŒ‰åˆ†æ•°æ’åº
        scored.sort(key=lambda x: x[0], reverse=True)
        return [exp for _, exp in scored[:top_k]]
    
    def format_experiences_for_prompt(
        self,
        experiences: list[Experience],
        max_length: int = 2000
    ) -> str:
        """å°†ç»éªŒæ ¼å¼åŒ–ä¸º prompt å¯ç”¨çš„æ–‡æœ¬"""
        if not experiences:
            return ""
        
        lines = ["## ç›¸å…³å†å²ç»éªŒ\n"]
        total_length = 0
        
        for i, exp in enumerate(experiences, 1):
            exp_text = f"""
### ç»éªŒ {i}
**é—®é¢˜**: {exp.problem[:200]}
**è§£å†³æ–¹æ¡ˆ**: {exp.solution[:300]}
**ä½¿ç”¨çš„å·¥å…·**: {', '.join(exp.tools_used[:5])}
**å…³é”®æ­¥éª¤**: {'; '.join(exp.steps[:3])}
"""
            if exp.docs_consulted:
                exp_text += f"**å‚è€ƒæ–‡æ¡£**: {', '.join(exp.docs_consulted[:2])}\n"
            
            if total_length + len(exp_text) > max_length:
                break
            
            lines.append(exp_text)
            total_length += len(exp_text)
        
        lines.append("\nè¯·å‚è€ƒä»¥ä¸Šç»éªŒï¼Œä½†æ ¹æ®å½“å‰æƒ…å†µçµæ´»è°ƒæ•´ã€‚\n")
        return "".join(lines)
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_experiences": 0,
            "successful": 0,
            "failed": 0,
            "vector_db_available": self._initialized
        }
        
        if self._initialized and self.collection:
            stats["total_experiences"] = self.collection.count()
        
        if os.path.exists(self.json_backup_path):
            try:
                with open(self.json_backup_path, "r", encoding="utf-8") as f:
                    experiences = json.load(f)
                    stats["json_backup_count"] = len(experiences)
                    stats["successful"] = sum(1 for e in experiences if e.get("success"))
                    stats["failed"] = len(experiences) - stats["successful"]
            except:
                pass
        
        return stats


# å…¨å±€å®ä¾‹
_experience_rag: Optional[ExperienceRAG] = None


def get_experience_rag(db_path: str = "./experience_db") -> ExperienceRAG:
    """è·å–å…¨å±€ RAG å®ä¾‹"""
    global _experience_rag
    if _experience_rag is None:
        _experience_rag = ExperienceRAG(db_path=db_path)
        _experience_rag.initialize()
    return _experience_rag
