"""Multi-AI collaborative agent with fallback to secondary AI."""

import asyncio
import json
import uuid
from typing import Any
from dataclasses import dataclass
from enum import Enum

from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage

from .orchestrator.llm_engine import create_llm_engine, LLMEngine
from .tools import execute_tool, get_all_tools
from .prompts import get_prompt
from .experience_rag import get_experience_rag, ExperienceRAG


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    NEEDS_INPUT = "needs_input"


@dataclass
class AIConfig:
    """Configuration for an AI model."""
    name: str
    provider: str
    model: str
    api_key: str
    role: str = "primary"  # primary, consultant, specialist
    base_url: str = None


class MultiAIAgent:
    """åŸºäºä»»åŠ¡å®ŒæˆçŠ¶æ€çš„å¤š AI åä½œ Agentã€‚
    
    æ ¸å¿ƒç†å¿µï¼šä»¥é—®é¢˜è§£å†³ä¸ºå¯¼å‘ï¼ŒæŒç»­å·¥ä½œç›´åˆ°ä»»åŠ¡å®Œæˆã€‚
    é‡åˆ°å›°éš¾æ—¶ä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£ï¼Œå¿…è¦æ—¶å’¨è¯¢å…¶ä»– AIã€‚
    æ”¯æŒ RAG ç»éªŒå­¦ä¹ ï¼Œä»å†å²æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹ ã€‚
    """
    
    def __init__(
        self,
        primary_config: AIConfig,
        secondary_configs: list[AIConfig] = None,
        max_retries_per_error: int = 3,
        search_attempts_before_consult: int = 2,
        prompt_type: str = "default",
        enable_rag: bool = True,
        experience_db_path: str = "./experience_db"
    ):
        self.primary_config = primary_config
        self.secondary_configs = secondary_configs or []
        self.max_retries_per_error = max_retries_per_error
        self.search_attempts_before_consult = search_attempts_before_consult
        self.prompt_type = prompt_type
        self.enable_rag = enable_rag
        self.experience_db_path = experience_db_path
        
        # Initialize engines
        self.primary_engine = None
        self.secondary_engines: dict[str, LLMEngine] = {}
        
        self.tools = get_all_tools()
        self.primary_llm = None
        
        # RAG ç»éªŒç³»ç»Ÿ
        self.experience_rag: ExperienceRAG = None
        
        # Tracking
        self.consultation_count = 0
    
    async def initialize(self) -> None:
        """Initialize all AI engines."""
        self.primary_engine = create_llm_engine(
            provider=self.primary_config.provider,
            model=self.primary_config.model,
            api_key=self.primary_config.api_key
        )
        self.primary_llm = self.primary_engine.bind_tools(self.tools)
        
        print(f"âœ… Primary AI: {self.primary_config.name} ({self.primary_config.model})")
        
        for config in self.secondary_configs:
            engine = create_llm_engine(
                provider=config.provider,
                model=config.model,
                api_key=config.api_key
            )
            self.secondary_engines[config.name] = engine
            print(f"âœ… Secondary AI: {config.name} ({config.model}) - {config.role}")
        
        print(f"âœ… Loaded {len(self.tools)} tools")
        
        # åˆå§‹åŒ– RAG ç»éªŒç³»ç»Ÿ
        if self.enable_rag:
            print("ğŸ“š Initializing experience RAG system...")
            self.experience_rag = get_experience_rag(self.experience_db_path)
            stats = self.experience_rag.get_stats()
            print(f"   ğŸ“Š {stats.get('total_experiences', 0)} experiences loaded")
    
    def _get_task_oriented_prompt(self) -> str:
        """è·å–ä»¥ä»»åŠ¡ä¸ºå¯¼å‘çš„ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = get_prompt(self.prompt_type)
        
        task_completion_instructions = """

## ä»»åŠ¡å®Œæˆæœºåˆ¶

ä½ å¿…é¡»åœ¨å›å¤ä¸­æ˜ç¡®æ ‡æ³¨ä»»åŠ¡çŠ¶æ€ã€‚åœ¨æœ€ç»ˆå›å¤æœ«å°¾ä½¿ç”¨ï¼š

- `[STATUS: COMPLETED]` - ä»»åŠ¡å·²å®Œæˆ
- `[STATUS: NEEDS_INPUT]` - éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯
- `[STATUS: FAILED: åŸå› ]` - ä»»åŠ¡å¤±è´¥
- `[STATUS: IN_PROGRESS]` - ä»»åŠ¡è¿›è¡Œä¸­ï¼Œéœ€è¦ç»§ç»­

### æ ¸å¿ƒåŸåˆ™

1. **æŒç»­å·¥ä½œç›´åˆ°å®Œæˆ**: ä¸è¦ä¸­é€”åœæ­¢ï¼Œé™¤éä»»åŠ¡å®Œæˆæˆ–éœ€è¦ç”¨æˆ·è¾“å…¥
2. **é‡åˆ°å›°éš¾ä¼˜å…ˆæŸ¥å®˜æ–¹æ–‡æ¡£**: 
   - æœç´¢ "[è½¯ä»¶å] official documentation [é—®é¢˜]"
   - ä½¿ç”¨ fetch_webpage è·å–æ–‡æ¡£è¯¦ç»†å†…å®¹
   - æŒ‰ç…§å®˜æ–¹æŒ‡å¯¼æ“ä½œ
3. **ä¸è¦è½»æ˜“æ”¾å¼ƒ**: å°è¯•å¤šç§æ–¹æ³•ï¼Œæœç´¢è§£å†³æ–¹æ¡ˆ
4. **å¦‚æœæ”¶åˆ°å…¶ä»– AI çš„å»ºè®®**: è®¤çœŸåˆ†æå¹¶æ‰§è¡Œ

### åˆ¤æ–­ä»»åŠ¡å®Œæˆçš„æ ‡å‡†

- ç”¨æˆ·è¦æ±‚çš„æ“ä½œå·²æˆåŠŸæ‰§è¡Œ
- ç”¨æˆ·çš„é—®é¢˜å·²å¾—åˆ°è§£ç­”
- ç»“æœå·²æ¸…æ™°å±•ç¤ºç»™ç”¨æˆ·
"""
        return base_prompt + task_completion_instructions
    
    def _parse_status(self, content: str) -> tuple[TaskStatus, str]:
        """ä»å›å¤ä¸­è§£æä»»åŠ¡çŠ¶æ€"""
        content_lower = content.lower()
        
        if "[status: completed]" in content_lower:
            return TaskStatus.COMPLETED, content.replace("[STATUS: COMPLETED]", "").strip()
        elif "[status: needs_input]" in content_lower:
            return TaskStatus.NEEDS_INPUT, content.replace("[STATUS: NEEDS_INPUT]", "").strip()
        elif "[status: failed" in content_lower:
            return TaskStatus.FAILED, content
        elif "[status: in_progress]" in content_lower:
            return TaskStatus.IN_PROGRESS, content.replace("[STATUS: IN_PROGRESS]", "").strip()
        
        return TaskStatus.IN_PROGRESS, content
    
    def _save_experience(
        self,
        problem: str,
        solution: str,
        steps: list[str],
        tools_used: list[str],
        errors: list[str],
        docs_consulted: list[str],
        success: bool
    ):
        """ä¿å­˜ç»éªŒåˆ° RAG ç³»ç»Ÿ"""
        if not self.experience_rag:
            return
        
        try:
            exp_id = self.experience_rag.save_experience(
                problem=problem,
                solution=solution[:1000],  # é™åˆ¶é•¿åº¦
                steps=steps[-10:],  # æœ€å 10 æ­¥
                tools_used=tools_used,
                errors_encountered=errors[-5:],  # æœ€å 5 ä¸ªé”™è¯¯
                docs_consulted=docs_consulted[-5:],
                success=success
            )
            if success:
                print(f"   ğŸ’¾ Experience saved: {exp_id}")
        except Exception as e:
            print(f"   âš ï¸ Failed to save experience: {e}")
    
    async def consult_secondary_ai(
        self,
        ai_name: str,
        problem_summary: str,
        attempted_solutions: list[str],
        errors: list[str],
        docs_consulted: list[str] = None
    ) -> str:
        """Consult a secondary AI for help."""
        if ai_name not in self.secondary_engines:
            return f"Secondary AI '{ai_name}' not configured"
        
        engine = self.secondary_engines[ai_name]
        
        consultation_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“å®¶é¡¾é—®ï¼Œå¦ä¸€ä¸ª AI åŠ©æ‰‹åœ¨è§£å†³é—®é¢˜æ—¶é‡åˆ°äº†å›°éš¾ï¼Œéœ€è¦ä½ çš„å¸®åŠ©ã€‚

## åŸå§‹é—®é¢˜
{problem_summary}

## å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
{chr(10).join(f"- {s}" for s in attempted_solutions) if attempted_solutions else "æ— "}

## é‡åˆ°çš„é”™è¯¯
{chr(10).join(f"- {e}" for e in errors) if errors else "æ— "}

## å·²æŸ¥é˜…çš„æ–‡æ¡£
{chr(10).join(f"- {d}" for d in (docs_consulted or [])) if docs_consulted else "æ— "}

## è¯·æ±‚
è¯·åˆ†æè¿™ä¸ªé—®é¢˜ï¼Œæä¾›ï¼š
1. é—®é¢˜çš„æ ¹æœ¬åŸå› åˆ†æ
2. æ¨èæŸ¥é˜…çš„å®˜æ–¹æ–‡æ¡£é“¾æ¥
3. å…·ä½“çš„è§£å†³æ­¥éª¤ï¼ˆå¯ä»¥ç›´æ¥æ‰§è¡Œçš„å‘½ä»¤ï¼‰
4. å¯èƒ½çš„æ›¿ä»£æ–¹æ¡ˆ

è¯·ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚"""

        print(f"\n   ğŸ¤ Consulting {ai_name}...")
        
        response = await engine.llm.ainvoke([HumanMessage(content=consultation_prompt)])
        self.consultation_count += 1
        
        return response.content
    
    async def chat(self, message: str) -> str:
        """åŸºäºä»»åŠ¡å®ŒæˆçŠ¶æ€çš„å¯¹è¯å¾ªç¯ï¼Œæ”¯æŒå¤š AI åä½œå’Œ RAG ç»éªŒå­¦ä¹ """
        if not self.primary_llm:
            await self.initialize()
        
        system_prompt = self._get_task_oriented_prompt()
        
        # RAG: æ£€ç´¢ç›¸å…³ç»éªŒ
        experience_context = ""
        if self.experience_rag:
            similar_experiences = self.experience_rag.search_similar(message, top_k=3)
            if similar_experiences:
                experience_context = self.experience_rag.format_experiences_for_prompt(similar_experiences)
                print(f"   ğŸ“š Found {len(similar_experiences)} relevant experiences")
        
        # æ„å»ºæ¶ˆæ¯
        if experience_context:
            system_prompt = system_prompt + "\n" + experience_context
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=message)
        ]
        
        # è¿½è¸ªçŠ¶æ€ï¼ˆç”¨äºä¿å­˜ç»éªŒï¼‰
        error_tracker = {}
        total_tool_calls = 0
        consecutive_no_progress = 0
        last_tool_results = []
        
        attempted_solutions = []
        all_steps = []  # è®°å½•æ‰€æœ‰æ­¥éª¤
        errors = []
        docs_consulted = []
        tools_used = []
        search_count = 0
        consulted = False
        final_response = ""
        task_success = False
        
        while True:
            # è°ƒç”¨ä¸» LLM
            response = await self.primary_llm.ainvoke(messages)
            messages.append(response)
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥çŠ¶æ€
            if not response.tool_calls:
                status, clean_content = self._parse_status(response.content)
                final_response = clean_content
                
                if status == TaskStatus.COMPLETED:
                    print("   âœ… Task completed")
                    task_success = True
                    # ä¿å­˜æˆåŠŸç»éªŒ
                    self._save_experience(
                        message, clean_content, all_steps, tools_used,
                        errors, docs_consulted, success=True
                    )
                    return clean_content
                elif status == TaskStatus.NEEDS_INPUT:
                    print("   â“ Needs user input")
                    return clean_content
                elif status == TaskStatus.FAILED:
                    print("   âŒ Task failed")
                    # ä¿å­˜å¤±è´¥ç»éªŒï¼ˆä¹Ÿæœ‰ä»·å€¼ï¼‰
                    self._save_experience(
                        message, clean_content, all_steps, tools_used,
                        errors, docs_consulted, success=False
                    )
                    return clean_content
                else:
                    consecutive_no_progress += 1
                    if consecutive_no_progress >= 2:
                        # å‡è®¾å®Œæˆï¼Œä¿å­˜ç»éªŒ
                        self._save_experience(
                            message, response.content, all_steps, tools_used,
                            errors, docs_consulted, success=True
                        )
                        return response.content
                    messages.append(HumanMessage(
                        content="è¯·ç¡®è®¤ä»»åŠ¡æ˜¯å¦å®Œæˆï¼Œå¹¶æ ‡æ³¨çŠ¶æ€ [STATUS: COMPLETED] æˆ–ç»§ç»­æ‰§è¡Œã€‚"
                    ))
                    continue
            
            consecutive_no_progress = 0
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            current_results = []
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]
                
                total_tool_calls += 1
                print(f"   ğŸ”§ [{total_tool_calls}] {tool_name}")
                if tool_args:
                    args_str = str(tool_args)
                    if len(args_str) > 60:
                        args_str = args_str[:60] + "..."
                    print(f"      Args: {args_str}")
                
                result = await execute_tool(tool_name, tool_args)
                current_results.append((tool_name, result))
                
                # è®°å½•æ­¥éª¤å’Œå·¥å…·
                step_desc = f"{tool_name}: {str(tool_args)[:100]}"
                all_steps.append(step_desc)
                if tool_name not in tools_used:
                    tools_used.append(tool_name)
                
                # è¿½è¸ªå°è¯•
                if tool_name == "run_command":
                    attempted_solutions.append(tool_args.get("command", ""))
                elif tool_name == "web_search":
                    search_count += 1
                elif tool_name == "fetch_webpage":
                    docs_consulted.append(tool_args.get("url", ""))
                
                # æ£€æŸ¥é”™è¯¯
                try:
                    result_data = json.loads(result)
                    is_error = result_data.get("error", False)
                    error_msg = result_data.get("message", "")
                except:
                    is_error = False
                    error_msg = ""
                
                if is_error:
                    error_key = f"{tool_name}:{error_msg[:50]}"
                    error_tracker[error_key] = error_tracker.get(error_key, 0) + 1
                    errors.append(error_msg)
                    
                    print(f"   âŒ Error: {error_msg[:60]}")
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                    if error_tracker[error_key] >= self.max_retries_per_error:
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å’¨è¯¢å…¶ä»– AI
                        should_consult = (
                            not consulted and
                            self.secondary_engines and
                            search_count >= self.search_attempts_before_consult
                        )
                        
                        if should_consult:
                            consulted = True
                            secondary_name = list(self.secondary_engines.keys())[0]
                            advice = await self.consult_secondary_ai(
                                secondary_name,
                                message,
                                attempted_solutions,
                                errors,
                                docs_consulted
                            )
                            
                            consultation_msg = f"""
[æ¥è‡ª {secondary_name} çš„ä¸“å®¶å»ºè®®]

{advice}

è¯·æ ¹æ®ä»¥ä¸Šå»ºè®®ï¼Œé‡æ–°å°è¯•è§£å†³é—®é¢˜ã€‚ä¼˜å…ˆæŒ‰ç…§å»ºè®®ä¸­æåˆ°çš„å®˜æ–¹æ–‡æ¡£æ“ä½œã€‚"""
                            
                            messages.append(ToolMessage(content=result, tool_call_id=tool_id))
                            messages.append(HumanMessage(content=consultation_msg))
                            error_tracker[error_key] = 0  # é‡ç½®è®¡æ•°
                            continue
                        else:
                            # æç¤ºä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£
                            hint = f"""
è¿™ä¸ªé”™è¯¯å·²ç»å‡ºç° {error_tracker[error_key]} æ¬¡äº†: {error_msg}

è¯·æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•è§£å†³:
1. **ä¼˜å…ˆæŸ¥é˜…å®˜æ–¹æ–‡æ¡£**: ä½¿ç”¨ web_search æœç´¢ "[è½¯ä»¶å] official documentation [é”™è¯¯å…³é”®è¯]"
2. ä½¿ç”¨ fetch_webpage è·å–å®˜æ–¹æ–‡æ¡£çš„è¯¦ç»†å†…å®¹
3. æ ¹æ®å®˜æ–¹æ–‡æ¡£çš„æŒ‡å¯¼é‡æ–°å°è¯•
4. å¦‚æœå®˜æ–¹æ–‡æ¡£æ²¡æœ‰ç­”æ¡ˆï¼Œå†æœç´¢ç¤¾åŒºè§£å†³æ–¹æ¡ˆ (Stack Overflow, GitHub Issues)
5. å¦‚æœç¡®å®æ— æ³•è§£å†³ï¼Œæ ‡è®° [STATUS: FAILED: åŸå› ]
"""
                            messages.append(ToolMessage(content=result, tool_call_id=tool_id))
                            messages.append(HumanMessage(content=hint))
                            continue
                else:
                    print(f"   âœ“ Success")
                
                messages.append(ToolMessage(content=result, tool_call_id=tool_id))
            
            # æ£€æµ‹å¾ªç¯
            if current_results == last_tool_results:
                consecutive_no_progress += 1
                if consecutive_no_progress >= 3:
                    messages.append(HumanMessage(
                        content="æ£€æµ‹åˆ°é‡å¤æ“ä½œã€‚è¯·å°è¯•ä¸åŒçš„æ–¹æ³•ï¼Œæˆ–æ ‡è®° [STATUS: COMPLETED]ã€‚"
                    ))
            else:
                last_tool_results = current_results
    
    async def run_interactive(self) -> None:
        """Run in interactive mode."""
        await self.initialize()
        
        print("\n" + "=" * 60)
        print("ğŸ¤– Multi-AI Linux Agent - ä»»åŠ¡å¯¼å‘æ¨¡å¼")
        print("=" * 60)
        print(f"Primary: {self.primary_config.name}")
        for cfg in self.secondary_configs:
            print(f"Consultant: {cfg.name} ({cfg.role})")
        print("-" * 60)
        print("Commands: 'quit', 'help', 'stats'")
        print("-" * 60 + "\n")
        
        while True:
            try:
                user_input = input("You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ("quit", "exit"):
                    print("\nGoodbye! ğŸ‘‹")
                    break
                
                if user_input.lower() == "stats":
                    print(f"\nğŸ“Š AI Consultations: {self.consultation_count}")
                    if self.experience_rag:
                        rag_stats = self.experience_rag.get_stats()
                        print(f"ğŸ“š Experiences: {rag_stats.get('total_experiences', 0)} total")
                        print(f"   âœ… Successful: {rag_stats.get('successful', 0)}")
                        print(f"   âŒ Failed: {rag_stats.get('failed', 0)}")
                        print(f"   ğŸ’¾ Vector DB: {'Yes' if rag_stats.get('vector_db_available') else 'No (using JSON)'}")
                    print()
                    continue
                
                if user_input.lower() == "help":
                    print("""
ç¤ºä¾‹:
  - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  - å¸®æˆ‘é…ç½® nginx åå‘ä»£ç†
  - å¦‚ä½•ä¼˜åŒ– MySQL æ€§èƒ½
  - æ’æŸ¥æœåŠ¡å™¨ CPU å ç”¨è¿‡é«˜çš„é—®é¢˜
  - åˆ›å»ºä¸€ä¸ªç›‘æ§è„šæœ¬
""")
                    continue
                
                print("\nğŸ¤” Working on your task...\n")
                response = await self.chat(user_input)
                print(f"\nAgent: {response}\n")
                
            except KeyboardInterrupt:
                print("\n\nâš ï¸ Interrupted.\n")
            except EOFError:
                break


def load_config_from_file(config_path: str = None):
    """Load configuration from YAML file."""
    import os
    from .common.config import MultiAgentConfig
    
    if config_path is None:
        for path in ["config.yaml", "config.yml"]:
            if os.path.exists(path):
                config_path = path
                break
    
    if config_path and os.path.exists(config_path):
        print(f"ğŸ“„ Loading config from: {config_path}")
        return MultiAgentConfig.from_yaml(config_path)
    
    return None


def load_config_from_env():
    """Load configuration from environment variables (fallback)."""
    import os
    
    deepseek_key = os.environ.get("DEEPSEEK_API_KEY", "")
    openai_key = os.environ.get("OPENAI_API_KEY", "")
    gemini_key = os.environ.get("GEMINI_API_KEY", "")
    
    if not deepseek_key and not openai_key and not gemini_key:
        return None, None
    
    if deepseek_key:
        primary = AIConfig(name="DeepSeek", provider="deepseek", 
                          model="deepseek-chat", api_key=deepseek_key, role="primary")
    elif openai_key:
        primary = AIConfig(name="GPT-4", provider="openai",
                          model="gpt-4o", api_key=openai_key, role="primary")
    else:
        primary = AIConfig(name="Gemini", provider="gemini",
                          model="gemini-2.5-flash", api_key=gemini_key, role="primary")
    
    secondary = []
    if gemini_key and primary.provider != "gemini":
        secondary.append(AIConfig(name="Gemini-Consultant", provider="gemini",
                                  model="gemini-2.5-flash", api_key=gemini_key, role="consultant"))
    if openai_key and primary.provider != "openai":
        secondary.append(AIConfig(name="GPT-4-Consultant", provider="openai",
                                  model="gpt-4o", api_key=openai_key, role="consultant"))
    if deepseek_key and primary.provider != "deepseek":
        secondary.append(AIConfig(name="DeepSeek-Consultant", provider="deepseek",
                                  model="deepseek-chat", api_key=deepseek_key, role="consultant"))
    
    return primary, secondary


async def main():
    """Main entry point."""
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description="Multi-AI Linux Agent")
    parser.add_argument("-c", "--config", help="Path to config.yaml file")
    args = parser.parse_args()
    
    config = load_config_from_file(args.config)
    
    if config:
        primary = AIConfig(
            name=config.primary_ai.name,
            provider=config.primary_ai.provider,
            model=config.primary_ai.model,
            api_key=config.primary_ai.api_key,
            role="primary"
        )
        secondary = [
            AIConfig(
                name=ai.name,
                provider=ai.provider,
                model=ai.model,
                api_key=ai.api_key,
                role=ai.role
            ) for ai in config.secondary_ais
        ]
        max_retries = config.agent.max_retries
        search_attempts = config.agent.search_attempts_before_consult
    else:
        print("ğŸ“„ No config file found, using environment variables")
        primary, secondary = load_config_from_env()
        max_retries = 3
        search_attempts = 2
    
    if not primary or not primary.api_key:
        print("Error: No API key configured!")
        print("\nOption 1: Create config.yaml from config.example.yaml")
        print("Option 2: Set environment variables:")
        print("  - DEEPSEEK_API_KEY")
        print("  - OPENAI_API_KEY") 
        print("  - GEMINI_API_KEY")
        sys.exit(1)
    
    agent = MultiAIAgent(
        primary_config=primary,
        secondary_configs=secondary,
        max_retries_per_error=max_retries,
        search_attempts_before_consult=search_attempts,
        prompt_type="default"
    )
    
    await agent.run_interactive()


if __name__ == "__main__":
    asyncio.run(main())
